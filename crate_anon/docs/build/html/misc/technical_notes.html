
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>12. Technical notes &#8212; CRATE  documentation</title>
    <link rel="stylesheet" href="../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/crate_docs.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="13. Upgrading CRATE" href="upgrading.html" />
    <link rel="prev" title="11. Troubleshooting" href="troubleshooting.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="upgrading.html" title="13. Upgrading CRATE"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="troubleshooting.html" title="11. Troubleshooting"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">CRATE  documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="technical-notes">
<h1>12. Technical notes<a class="headerlink" href="#technical-notes" title="Permalink to this headline">¶</a></h1>
<div class="section" id="resolved-bugs-elsewhere-previously-affecting-crate">
<h2>12.1. Resolved bugs elsewhere, previously affecting CRATE<a class="headerlink" href="#resolved-bugs-elsewhere-previously-affecting-crate" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p class="first">When mounted other than at /, using FORCE_SCRIPT_NAME, the “View site” link
of Django admin sites points to / rather than the approriate site root.
This is fixed in Django 1.10 (not yet released 2015-11-23, but out by
2017-02-09).</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/stephenmcd/mezzanine/issues/389">https://github.com/stephenmcd/mezzanine/issues/389</a>
<a class="reference external" href="https://docs.djangoproject.com/en/dev/releases/1.10/">https://docs.djangoproject.com/en/dev/releases/1.10/</a></p>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="cross-platform-hosting">
<h2>12.2. Cross-platform hosting<a class="headerlink" href="#cross-platform-hosting" title="Permalink to this headline">¶</a></h2>
<p>For Ubuntu, CRATE is packaged as a Debian .DEB file and will install itself,
though will not configure the web front end (intrinsically a separate
configuration task).</p>
<p>If you have to run under Windows, then one option is a VirtualBox
(<a class="reference external" href="https://www.virtualbox.org/">https://www.virtualbox.org/</a>).</p>
<p>In the conversion from Ubuntu to Windows:</p>
<p><strong>Python code, i.e. CRATE itself</strong></p>
<p>Cross-platform</p>
<p><strong>Database connections</strong></p>
<p>All configurable, and Windows connections available for all. MySQL supported
under Windows.</p>
<p><strong>Text extraction tools</strong></p>
<p>The Linux tools used are unrtf (.RTF), pdftotext (.PDF), antiword (.DOC),
strings (anything). They are generally very fast. CRATE calls them by name.</p>
<ul class="simple">
<li>unrtf is available for Windows (license: GPL)
(<a class="reference external" href="https://www.gnu.org/software/unrtf/">https://www.gnu.org/software/unrtf/</a>;
<a class="reference external" href="http://gnuwin32.sourceforge.net/packages/unrtf.htm">http://gnuwin32.sourceforge.net/packages/unrtf.htm</a>).</li>
<li>pdftotext is available for Windows as part of Xpdf (license: GPL)
(<a class="reference external" href="http://www.foolabs.com/xpdf/">http://www.foolabs.com/xpdf/</a>).</li>
<li>antiword (<a class="reference external" href="http://www.winfield.demon.nl/">http://www.winfield.demon.nl/</a>) can be compiled for Windows and is
available as a binary
(<a class="reference external" href="http://www-stud.rbi.informatik.uni-frankfurt.de/~markus/antiword/">http://www-stud.rbi.informatik.uni-frankfurt.de/~markus/antiword/</a>).</li>
<li>strings has an equivalent for Windows
(<a class="reference external" href="https://technet.microsoft.com/en-us/sysinternals/bb897439.aspx">https://technet.microsoft.com/en-us/sysinternals/bb897439.aspx</a>).</li>
</ul>
<p><em>Users on Windows should install these tools so that they’re visible to CRATE
via the PATH.</em></p>
<p><strong>Web framework (Gunicorn, with e.g. Apache as a front end)</strong></p>
<p>Gunicorn is UNIX-only, although happily it installs without complaint on
Windows, so we don’t need to exclude it from the dependencies.</p>
<p>Alternatives include: (1) CherryPy. This is pure Python. It supports SSL and
serves static files. Let’s use it. (2) uWSGI: written in C and requires Cygwin;
probably overly complex. (3) Waitress
(<a class="reference external" href="https://pylons.readthedocs.org/projects/waitress/en/latest/">https://pylons.readthedocs.org/projects/waitress/en/latest/</a>). This doesn’t
support SSL but does support reverse proxying.</p>
<p>CherryPy works nicely; I’ve set up a launch script and default configuration.
(But see also: <a class="reference external" href="https://baxeico.wordpress.com/2013/10/13/django-on-windows/">https://baxeico.wordpress.com/2013/10/13/django-on-windows/</a>;
<a class="reference external" href="http://tools.cherrypy.org/wiki/WindowsService">http://tools.cherrypy.org/wiki/WindowsService</a>.) <strong>This is also suitable for
Linux use.</strong> It uses a thread pool by default for its HTTP server. It runs as a
django manage.py command, so use it as <strong>crate_django_manage runcpserver</strong>. You
can append <code class="docutils literal notranslate"><span class="pre">--help</span></code> to get other options that you can use with the
CRATE_CHERRYPY_ARGS environment variable. There are also a few settings in
crateweb/config/settings.py that configure CherryPy, and quite a lot more in
crateweb/core/management/commands/runcpserver.py.</p>
<p><strong>Celery</strong></p>
<p>Celery is in Python, so is cross-platform. It can be run as a daemon/service
under Windows, using the Windows built-in Task Scheduler
(<a class="reference external" href="http://docs.celeryproject.org/en/latest/tutorials/daemonizing.html">http://docs.celeryproject.org/en/latest/tutorials/daemonizing.html</a>;
<a class="reference external" href="https://www.calazan.com/windows-tip-run-applications-in-the-background-using-task-scheduler/">https://www.calazan.com/windows-tip-run-applications-in-the-background-using-task-scheduler/</a>;
you use the virtualenv’s ‘crate/bin/celeryd’ as the process). Services can also
be installed from Python. [Use ‘pip install pypiwin32’. (It’s a pip-only
version of pywin32, I think.) That makes available the libraries pythoncom
(unnecessary?), win32serviceutil, win32service, win32event, servicemanager.
Then see <a class="reference external" href="http://stackoverflow.com/questions/32404">http://stackoverflow.com/questions/32404</a> for how to install/run Python
code as a service.]</p>
<p>It did need some fixing, which was hard: key parameters to the “celery worker”
command were “–concurrency=4” and “–pool=solo”. See comments in
crateweb/consent/celery.py.</p>
<p><strong>RabbitMQ</strong></p>
<p>RabbitMQ supports Windows directly and runs as a service
(<a class="reference external" href="https://www.rabbitmq.com/install-windows.html">https://www.rabbitmq.com/install-windows.html</a>).</p>
<p><strong>supervisord</strong></p>
<p>supervisord is used under Linux to control (a) celery and (b) gunicorn. It does
not run under Windows
(<a class="reference external" href="http://supervisord.org/introduction.html#platform-requirements">http://supervisord.org/introduction.html#platform-requirements</a> ; though see
<a class="reference external" href="http://stackoverflow.com/questions/7629813">http://stackoverflow.com/questions/7629813</a> as you can run supervisord under
Cygwin). Under Windows, we need to run (a) celery and (b) CherryPy. For Celery,
this function is replaced by the Windows Task Scheduler. For CherryPy, there is
also a daemon script. It can be run from the command line with <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-c</span>
<span class="pre">“from</span> <span class="pre">cherrypy.daemon</span> <span class="pre">import</span> <span class="pre">run;</span> <span class="pre">run()”</span></code>. (An aside: note also Monit; not
free, but potentially good, in the UNIX environment; <a class="reference external" href="https://mmonit.com/">https://mmonit.com/</a>.) See
also django-windows-tools
(<a class="reference external" href="http://django-windows-tools.readthedocs.org/en/latest/index.html">http://django-windows-tools.readthedocs.org/en/latest/index.html</a>; this seems
to be Python 2 only (as of 2016-05-11).).</p>
<p>The practical answer was to write a small Windows service that runs other
processes.</p>
<p><strong>MySQL standalone auditor</strong></p>
<p>Ditched; MySQL now supports adequate auditing itself. In mysql.cnf:</p>
<ul class="simple">
<li>Set ‘log_output = TABLE’ (to use the table mysql.general_log), ‘log_output =
FILE’ (to use the file specified by the ‘general_log_file’ variable), or
‘log_output = FILE,TABLE’ for both.</li>
<li>Set ‘general_log = 1’.</li>
</ul>
<p>Restart MySQL (<a class="reference external" href="https://dev.mysql.com/doc/refman/5.7/en/log-destinations.html">https://dev.mysql.com/doc/refman/5.7/en/log-destinations.html</a>).
The TABLE form of the log neatly includes username and queries. The
mysql.general_log.thread_id field is used as the ‘id’ column of the disk log;
you can in principle work out user information from the Connect entries that
occur prior to queries, but the TABLE form provides a much more convenient way
of working out user/query mappings. It will hit performance, though.</p>
<p><strong>Library dependencies</strong></p>
<p>DOCX extraction preferred to use python-docx, which uses lxml, which has C
dependencies and is therefore fiddly to install on arbitrary Windows systems
(i.e. is not guaranteed to be installed by pip). One option would be for the
user to install lxml from e.g. a binary repository
(<a class="reference external" href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml">http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml</a>), but instead I rewrote
rnc_extract_text.py (in cardinal_pythonlib) to use a pure Python approach that
also handles tables.</p>
</div>
<div class="section" id="converting-to-sqlalchemy">
<h2>12.3. Converting to SQLAlchemy<a class="headerlink" href="#converting-to-sqlalchemy" title="Permalink to this headline">¶</a></h2>
<p>See <code class="docutils literal notranslate"><span class="pre">test_sqla_reflection.py</span></code></p>
<ul>
<li><p class="first">Cataloguing databases: easy.</p>
</li>
<li><p class="first">Storing a datatype: a SQLAlchemy column type (coltype = col[‘type’])
String(length=10); str(coltype) looks like ‘VARCHAR(10)’, using a
dialect-free version, and repr(coltype) looks like ‘String(length=10)’.
Parsing the latter involves something akin to eval (maybe using ast). Parsing
the former… see sqlalchemy/dialects/mysql/base.py, particularly
_parse_column() and ischema_names. For dialect-specific things, you find
‘LONGBLOB’ (str) and ‘LONGBLOB()’ (repr). Dealt with by using the
str(coltype) method and adding a reverse lookup via SQLAlchemy dialect.</p>
</li>
<li><p class="first">SQL field comments: there is no standard cross-database way
(<a class="reference external" href="https://bitbucket.org/zzzeek/sqlalchemy/issues/1546/feature-request-commenting-db-objects">https://bitbucket.org/zzzeek/sqlalchemy/issues/1546/feature-request-commenting-db-objects</a>,
including my compilation of methods for different backends). The web
interface could read comments from the DD, but that introduces an otherwise
unnecessary dependence on a user-maintained file. Better to read just from
the database. <strong>When SQLAlchemy supports comments, set up CRATE’s Django code
to read them from all relevant backends (currently it is MySQL-specific).</strong></p>
</li>
<li><p class="first">Iteration by rows: if memory constraints become a real problem, consider
yield_per(); note that some DBAPIs fetch all rows anyway even if you use
cursor.fetchone(). [See e.g. MySQL/cursors.py; compare
CursorStoreResultMixIn.fetchone() and CursorUseResultMixIn.fetchone(). The
default, cursors.Cursor (used by Connection()), uses CursorStoreResultMixIn,
which keeps the resultset on the client side. See also e.g.
<a class="reference external" href="http://stackoverflow.com/questions/18193825/python-how-to-use-a-generator-to-avoid-sql-memory-issue">http://stackoverflow.com/questions/18193825/python-how-to-use-a-generator-to-avoid-sql-memory-issue</a>;
<a class="reference external" href="http://stackoverflow.com/questions/2067529/mysqldb-pulls-whole-query-result-in-one-chunk-always-even-if-i-just-do-a-fetchon">http://stackoverflow.com/questions/2067529/mysqldb-pulls-whole-query-result-in-one-chunk-always-even-if-i-just-do-a-fetchon</a>;
<a class="reference external" href="https://mail.python.org/pipermail/python-list/2006-June/370129.html">https://mail.python.org/pipermail/python-list/2006-June/370129.html</a>;
<a class="reference external" href="http://stackoverflow.com/questions/1145905/sqlalchemy-scan-huge-tables-using-orm">http://stackoverflow.com/questions/1145905/sqlalchemy-scan-huge-tables-using-orm</a>]</p>
</li>
<li><p class="first">INSERT… ON DUPLICATE KEY UPDATE: tricky
[<a class="reference external" href="http://stackoverflow.com/questions/6611563/sqlalchemy-on-duplicate-key-update">http://stackoverflow.com/questions/6611563/sqlalchemy-on-duplicate-key-update</a>;
<a class="reference external" href="https://gist.github.com/timtadh/7811458">https://gist.github.com/timtadh/7811458</a>;
<a class="reference external" href="https://www.reddit.com/r/Python/comments/p5grh/sqlalchemy_whats_the_idiomatic_way_of_writing/">https://www.reddit.com/r/Python/comments/p5grh/sqlalchemy_whats_the_idiomatic_way_of_writing/</a>;
<a class="reference external" href="https://groups.google.com/forum/#!topic/sqlalchemy/RJQHYOpmMCo">https://groups.google.com/forum/#!topic/sqlalchemy/RJQHYOpmMCo</a>;
<a class="reference external" href="https://bitbucket.org/zzzeek/sqlalchemy/issues/3113/warning-for-custom-insert-mysql">https://bitbucket.org/zzzeek/sqlalchemy/issues/3113/warning-for-custom-insert-mysql</a>;
<a class="reference external" href="http://stackoverflow.com/questions/1382469/sqlalchemy-easy-way-to-insert-or-update">http://stackoverflow.com/questions/1382469/sqlalchemy-easy-way-to-insert-or-update</a>
<a class="reference external" href="https://bitbucket.org/zzzeek/sqlalchemy/issues/960">https://bitbucket.org/zzzeek/sqlalchemy/issues/960</a>]. Used a custom directive
(with compile-specific-to-MySQL option) to append SQL.</p>
</li>
<li><p class="first">Character set: tricky. Getting this wrong leads to MySQL ‘1336, Incorrect
string value’ errors or Python ‘UnicodeEncodeError’ errors on insert. MySQL
has character set/collation settings for: client, server, database, table,
column… [To view:
<a class="reference external" href="http://makandracards.com/makandra/2529-show-and-change-mysql-default-character-set">http://makandracards.com/makandra/2529-show-and-change-mysql-default-character-set</a>.]
In SQLAlchemy, specify the character set for the connection and,
particularly, for creating the destination table. [See
<a class="reference external" href="http://docs.sqlalchemy.org/en/latest/dialects/mysql.html">http://docs.sqlalchemy.org/en/latest/dialects/mysql.html</a> . Specify options
like mysql_charset either in the Table() definition (SQLAlchemy Core) or the
__table_args__ dictionary (SQLAlchemy ORM):
<a class="reference external" href="http://stackoverflow.com/questions/8971960">http://stackoverflow.com/questions/8971960</a>.] Database URLs should include
‘?charset=utf8’ or similar, and the rest is handled internally.</p>
</li>
<li><p class="first">CREATE FULLTEXT INDEX: MySQL-specific
[<a class="reference external" href="http://stackoverflow.com/questions/14971619/proper-use-of-mysql-full-text-search-with-sqlalchemy">http://stackoverflow.com/questions/14971619/proper-use-of-mysql-full-text-search-with-sqlalchemy</a>].
PostgreSQL supports full-text indexing but uses different methods
[<a class="reference external" href="http://www.postgresql.org/docs/9.1/static/textsearch-tables.html">http://www.postgresql.org/docs/9.1/static/textsearch-tables.html</a>]. Handled
with dialect-specific code.</p>
</li>
<li><p class="first"><strong>MySQL settings: configure using ``/etc/mysql/my.cnf`` or equivalent.</strong> To
walk through: the InnoDB storage engine is probably best, with transactions
and savepoints (see “SHOW ENGINES”); it’s the default. As of MySQL 5.6, it
also supports FULLTEXT indexes. It can be asked to store tables using a file
per table; this is true by default for versions ≤5.5.6 and false by default
for ≥5.5.7
[<a class="reference external" href="https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html">https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html</a>].
InnoDB can use the Antelope or Barracuda file format
[<a class="reference external" href="https://dev.mysql.com/doc/refman/5.7/en/innodb-file-format.html">https://dev.mysql.com/doc/refman/5.7/en/innodb-file-format.html</a>]; the
default became Barracuda for MySQL ≥5.7.7; Barracuda is fancier. It supports
options like DYNAMIC row formats. As of MySQL 5.7.9, one can specify the
default row format
[<a class="reference external" href="https://dev.mysql.com/doc/refman/5.7/en/innodb-row-format-specification.html">https://dev.mysql.com/doc/refman/5.7/en/innodb-row-format-specification.html</a>].
You can dynamically change a table’s file and row format
[<a class="reference external" href="http://stackoverflow.com/questions/8112517/alter-row-format-to-dynamic">http://stackoverflow.com/questions/8112517/alter-row-format-to-dynamic</a>].</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Example lines from /etc/mysql/my.cnf:
character_set_server = utf8
collation_server = utf8_unicode_ci
default_storage_engine = InnoDB
innodb_file_per_table = 1
innodb_file_format = Barracuda
innodb_default_row_format = DYNAMIC

# To alter row format dynamically later
# (e.g. from Antelope/COMPACT to Barracuda/DYNAMIC):
mysql&gt; ALTER TABLE databasename.tablename ROW_FORMAT=DYNAMIC;
# To confirm:
mysql&gt; SELECT * FROM information_schema.innodb_sys_tables WHERE name = ‘databasename/tablename’;

# To create a database with a specified charset/collation:
mysql&gt; CREATE DATABASE somedb DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_unicode_ci;

# To alter a table’s character set/collation:
# (http://stackoverflow.com/questions/742205)
# (http://stackoverflow.com/questions/766809)
mysql&gt; ALTER TABLE sometable CONVERT TO CHARACTER SET utf8 COLLATE utf8_unicode_ci;
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="installing-python-3-4-on-ubuntu-16-04">
<h2>12.4. Installing Python 3.4 on Ubuntu 16.04<a class="headerlink" href="#installing-python-3-4-on-ubuntu-16-04" title="Permalink to this headline">¶</a></h2>
<p>See
<a class="reference external" href="http://devmartin.com/blog/2016/04/creating-a-virtual-environment-with-python3.4-on-ubuntu-16.04-xenial-xerus/">http://devmartin.com/blog/2016/04/creating-a-virtual-environment-with-python3.4-on-ubuntu-16.04-xenial-xerus/</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo apt install build-essential checkinstall libreadline-gplv2-dev <span class="se">\</span>
    libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev <span class="se">\</span>
    libbz2-dev openssl

mkdir -p <span class="nv">$HOME</span>/opt
<span class="nb">cd</span> <span class="nv">$HOME</span>/opt
curl -O https://www.python.org/ftp/python/3.4.4/Python-3.4.4.tgz
tar xzvf Python-3.4.4.tgz
<span class="nb">cd</span> Python-3.4.4
./configure --enable-shared --prefix<span class="o">=</span>/usr/local <span class="nv">LDFLAGS</span><span class="o">=</span><span class="s2">&quot;-Wl,--rpath=/usr/local/lib&quot;</span>
sudo make altinstall

sudo python3.4 -m pip install --upgrade pip
sudo python3.4 -m pip install virtualenv
</pre></div>
</div>
</div>
<div class="section" id="transaction-count-always-0-for-sql-server-prohibiting-create-fulltext-index">
<h2>12.5. Transaction count always &gt;0 for SQL Server, prohibiting CREATE FULLTEXT INDEX<a class="headerlink" href="#transaction-count-always-0-for-sql-server-prohibiting-create-fulltext-index" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>SET IMPLICIT_TRANSACTIONS ON|OFF
<a class="reference external" href="https://msdn.microsoft.com/en-gb/library/ms187807.aspx">https://msdn.microsoft.com/en-gb/library/ms187807.aspx</a>
didn’t help</li>
<li>SQLSetConnectAttr()
<a class="reference external" href="https://docs.microsoft.com/en-us/sql/odbc/reference/syntax/sqlsetconnectattr-function">https://docs.microsoft.com/en-us/sql/odbc/reference/syntax/sqlsetconnectattr-function</a></li>
<li>ODBC commit mode
<a class="reference external" href="https://docs.microsoft.com/en-us/sql/odbc/reference/develop-app/commit-mode">https://docs.microsoft.com/en-us/sql/odbc/reference/develop-app/commit-mode</a></li>
<li>Other
<a class="reference external" href="http://dba.stackexchange.com/questions/43254/is-it-a-bad-practice-to-always-create-a-transaction">http://dba.stackexchange.com/questions/43254/is-it-a-bad-practice-to-always-create-a-transaction</a></li>
<li>SQLAlchemy and the Python DBAPI transaction rule even without “BEGIN”
<a class="reference external" href="https://news.ycombinator.com/item?id=4269241">https://news.ycombinator.com/item?id=4269241</a></li>
</ul>
</div>
<div class="section" id="celery-test-email-rdbm-task-missing-1-required-positional-argument-self">
<h2>12.6. Celery: test_email_rdbm_task() missing 1 required positional argument: ‘self’<a class="headerlink" href="#celery-test-email-rdbm-task-missing-1-required-positional-argument-self" title="Permalink to this headline">¶</a></h2>
<p>Change decorators from:</p>
<blockquote>
<div>&#64;shared_task
&#64;task(ignore_result=True)</div></blockquote>
<p>to</p>
<blockquote>
<div>&#64;shared_task(ignore_result=True)</div></blockquote>
</div>
<div class="section" id="sql-comments">
<h2>12.7. SQL comments<a class="headerlink" href="#sql-comments" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference external" href="https://bitbucket.org/zzzeek/sqlalchemy/issues/1546/feature-request-commenting-db-objects">https://bitbucket.org/zzzeek/sqlalchemy/issues/1546/feature-request-commenting-db-objects</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For column comments, I think the various DDLs are as follows:

Oracle
======

1. Adding during table creation:

    not possible?

2. Adding comments later:

    COMMENT ON TABLE sometable IS &#39;This is a table comment&#39;;
    COMMENT ON COLUMN sometable.somecol IS &#39;This is a column comment&#39;;

3. Retrieving:

    SELECT table_name, comments FROM all_tab_comments WHERE table_name = &#39;sometable&#39;;
    SELECT column_name, comments FROM all_col_comments WHERE table_name = &#39;sometable&#39;;

4. References

    https://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_4009.htm
    https://docs.oracle.com/cd/B28359_01/server.111/b28320/statviews_1036.htm
    https://docs.oracle.com/cd/B19306_01/server.102/b14237/statviews_2095.htm
    Note also alternative views (DBA_*, USER_* rather than ALL_*).

MySQL
=====

1. Adding during table creation:

    CREATE TABLE sometable (somecol INTEGER COMMENT &#39;this is a column comment&#39;) COMMENT &#39;this is a table comment&#39;;

2. Adding comments later:

    ALTER TABLE sometable COMMENT &#39;this is a table comment too&#39;;
    ALTER TABLE sometable CHANGE somecol somecol INTEGER COMMENT &#39;this is a column comment too&#39;;

3. Retrieving:

    SELECT table_schema, table_name, table_comment FROM information_schema.tables WHERE table_schema = DATABASE() AND table_name = &#39;sometable&#39;;
    SELECT table_schema, column_name, column_comment FROM information_schema.columns WHERE table_schema = DATABASE() AND table_name = &#39;sometable&#39;;

4. References

    http://dev.mysql.com/doc/refman/5.7/en/create-table.html
    http://dev.mysql.com/doc/refman/5.7/en/tables-table.html
    http://dev.mysql.com/doc/refman/5.7/en/columns-table.html

PostgreSQL
==========

1. Adding during table creation:

    not possible?

2. Adding comments later:

    COMMENT ON TABLE sometable IS &#39;This is a table comment&#39;;
    COMMENT ON COLUMN sometable.somecol IS &#39;This is a column comment&#39;;

3. Retrieving:

    (Uses internal OIDs to reference table number.)

    SELECT t.table_schema, t.table_name, pgd.description
    FROM pg_catalog.pg_statio_all_tables AS st
    INNER JOIN pg_catalog.pg_description pgd ON (pgd.objoid = st.relid)
    INNER JOIN information_schema.tables t ON (
        pgd.objsubid = 0 AND
        t.table_schema = st.schemaname AND
        t.table_name = st.relname)
    WHERE t.table_name = &#39;sometable&#39;;

    SELECT c.table_schema, c.table_name, c.column_name, pgd.description
    FROM pg_catalog.pg_statio_all_tables AS st
    INNER JOIN pg_catalog.pg_description pgd ON (pgd.objoid = st.relid)
    INNER JOIN information_schema.columns c ON (
        pgd.objsubid = c.ordinal_position AND
        c.table_schema = st.schemaname AND
        c.table_name = st.relname)
    WHERE c.table_name = &#39;sometable&#39;;

4. References

    http://www.postgresql.org/docs/9.1/static/sql-createtable.html
    http://www.postgresql.org/docs/9.2/static/sql-comment.html
    http://stackoverflow.com/questions/343138/retrieving-comments-from-a-postgresql-db
    http://www.postgresql.org/docs/8.3/static/catalog-pg-description.html
    http://www.postgresql.org/docs/9.2/static/monitoring-stats.html#PG-STATIO-ALL-TABLES-VIEW

MSSQL (SQL Server)
==================

- Unsupported in SQL. Possible using &quot;extended properties&quot;. A bit nasty, but...

1. Adding during table creation:

    not possible?

2. Adding comments later:

    EXEC sys.sp_addextendedproperty
        @name=N&#39;Description&#39;,
        @value=N&#39;This is a table comment&#39;,
        @level0type=N&#39;SCHEMA&#39;,
        @level0name=N&#39;dbo&#39;,
        @level1type=N&#39;TABLE&#39;,
        @level1name=N&#39;sometable&#39;
    GO
    EXEC sys.sp_addextendedproperty
        @name=N&#39;Description&#39;,
        @value=N&#39;This is a column comment&#39;,
        @level0type=N&#39;SCHEMA&#39;,
        @level0name=N&#39;dbo&#39;,
        @level1type=N&#39;TABLE&#39;,
        @level1name=N&#39;sometable&#39;,
        @level2type=N&#39;COLUMN&#39;,
        @level2name=N&#39;somecol&#39;
    GO

3. Retrieving:

    SELECT
        s.name AS schema_name,
        t.name AS table_name,
        CONVERT(VARCHAR(1000), x.value) AS table_comment -- is of type SQL_VARIANT
    FROM sys.tables t
    LEFT JOIN sys.extended_properties x ON t.object_id = x.major_id
    LEFT JOIN sys.schemas s on t.schema_id = s.schema_id
    WHERE x.minor_id = 0 AND t.name = &#39;sometable&#39;;

    SELECT
        s.name AS schema_name,
        t.name AS table_name,
        c.name AS column_name,
        CONVERT(VARCHAR(1000), x.value) AS column_comment
    FROM sys.columns c
    LEFT JOIN sys.extended_properties x ON (
        c.object_id = x.major_id AND
        c.column_id = x.minor_id
    )
    LEFT JOIN sys.tables t ON c.object_id = t.object_id
    LEFT JOIN sys.schemas s on t.schema_id = s.schema_id
    WHERE t.name = &#39;sometable&#39;;

4. References

    http://stackoverflow.com/questions/4586842/sql-comments-on-create-table-on-sql-server-2008
    https://msdn.microsoft.com/en-us/library/ms180047.aspx
    https://mrsql.wordpress.com/tag/sp_addextendedproperty/

SQLite
======

- Unsupported.

    http://www.sqlite.org/lang.html
</pre></div>
</div>
</div>
<div class="section" id="webnotes-txt">
<h2>12.8. webnotes.txt<a class="headerlink" href="#webnotes-txt" title="Permalink to this headline">¶</a></h2>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>===============================================================================
Early thoughts preceding Django, starting 19 Mar 2015
===============================================================================

    - output roughly sketched out
    - WSGI framework drafted

    - needs safe SQL creation framework
        - easy to make something too fiddly: http://www.ajaxquerybuilder.com/
    - needs session, security/users, main menu, audit
    - user accessing the destination database must be READ ONLY here

This kind of queries that might benefit from some autogeneration:

    SELECT
        master.rid, master.dob, ...
        secondtable.field1, secondtable.field2, ...
        thirdtable.field1, thirdtable.field2, ...
    FROM
        master
        INNER JOIN secondtable ON (secondtable.rid = master.rid)
        INNER JOIN thirdtable ON (thirdtable.rid = master.rid)
    WHERE
        MATCH(secondtable.field1) AGAINST (&#39;schizophrenia&#39;)
        OR MATCH(thirdtable.field1) AGAINST (&#39;schizophrenia&#39;)

However, it&#39;s not clear anything really improves on writing raw SQL; most
assisted query generation frameworks are quite crippled functionally. Simple
SQL also has the advantage of producing a clear tabular structure, without
nesting.

===============================================================================
SITE-SPECIFIC CONFIGURATION FILES FOR DJANGO
===============================================================================

Several methods; e.g.
    https://code.djangoproject.com/wiki/SplitSettings#ini-stylefilefordeployment
    https://code.djangoproject.com/wiki/SplitSettings#Multiplesettingfilesimportingfromeachother
The question is which works best with WSGI, where we have public (repository)
code and secret (site-specific) settings, and in principle might want to run
more than one instance of the application on a single server.

Using Apache&#39;s SetEnv and then reading the WSGI environment (as I currently do
for CamCOPS, Sep 2015) can be flaky with Django, so should be avoided:
    http://stackoverflow.com/questions/19754834/access-apache-setenv-variable-from-django-wsgi-py-file
Note that it appears possible, and lots of people advocate it, but Graham D.&#39;s
point is cautionary, and he wrote mod_wsgi.

Therefore, follow Graham Dumpleton&#39;s suggestion, e.g. as follows:

- hard-code the filename &#39;crate_local_settings.py&#39;, so that the Django
  settings.py does &#39;from crate_local_settings import *&#39;
- define settings for multiple apps by creating e.g.
    /etc/crate_instance_1/crate_local_settings.py
    /etc/crate_instance_2/crate_local_settings.py
- set the WSGI &quot;python-path&quot; (more or less equivalent to the normal environment
  variable PYTHONPATH) to include the relevant /etc/[something] directory

===============================================================================
DJANGO PROJECT
===============================================================================

# -----------------------------------------------------------------------------
# SYSTEM-WIDE OPTIONAL EXTRAS
# -----------------------------------------------------------------------------

sudo apt-get install sqliteman

# -----------------------------------------------------------------------------
# VIRTUALENV; PYTHON PREREQUISITES
# -----------------------------------------------------------------------------

# (a) System-wide installation of pip and virtualenv

sudo apt-get install python3-pip  # pip for Python 3
sudo pip3 install virtualenv  # Python 3 version of virtualenv

# (b) Creation of clean Python 3 virtual environment, with its own pip

export VENV=~/tmp/crate_virtualenv
mkdir -p $VENV
virtualenv --python=/usr/bin/python3.4 $VENV
export PIP=$VENV/bin/pip
export PYTHON=$VENV/bin/python

# (c) Installation of packages into virtual environment

$PIP install django  # Django
export DJANGO_ADMIN=$VENV/bin/django-admin.py
$PIP install mysqlclient  # Python 3 replacement for MySQLdb
$PIP install django-sslserver  # SSL development server
$PIP install django-picklefield  # PickleField

# -----------------------------------------------------------------------------
# DJANGO PROJECT CREATION
# -----------------------------------------------------------------------------

# Check versions
$PYTHON -c &quot;import django; print(django.get_version())&quot;
$DJANGO_ADMIN version
# ... is currently 1.8.4

$DJANGO_ADMIN startproject crateweb

# Edit manage.py, changing
#       #!/usr/bin/env python
# to
#       #!/usr/bin/env python
# ... or Python 2 and an old version of Django may be used.

# -----------------------------------------------------------------------------
# DJANGO PROJECT MANAGEMENT
# -----------------------------------------------------------------------------

export CRATE_BASE=~/Documents/code/crate
export CRATE_DJANGO_ROOT=$CRATE_BASE/webfrontend/crateweb
export CRATE_MANAGE=&quot;$PYTHON $CRATE_DJANGO_ROOT/manage.py&quot;
. $CRATE_BASE/webfrontend/SET_PATHS.sh
$CRATE_MANAGE  # shouldn&#39;t produce an error

-------------------------------------------------------------------------------
RUN TEST SERVER
-------------------------------------------------------------------------------

# For HTTP:
$CRATE_MANAGE runserver
# ... now browse to http://127.0.0.1:8000/

# For HTTPS (having installed/configured django-sslserver)
$CRATE_MANAGE runsslserver
# ... now browse to https://127.0.0.1:8000/

-------------------------------------------------------------------------------
GRANT READ-ONLY ACCESS TO MYSQL RESEARCH DATABASE
-------------------------------------------------------------------------------

mysql -u root -p
mysql&gt; GRANT SELECT ON anonymous_output.* TO &#39;researcher&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;password&#39;;

-------------------------------------------------------------------------------
CREATE/RECREATE TABLES
-------------------------------------------------------------------------------

# If models have changed:
$CRATE_MANAGE makemigrations [appname]

# To see what it&#39;ll do, e.g.
$CRATE_MANAGE sqlmigrate research 0001  # ... appname, migration_number

# Then:
$CRATE_MANAGE migrate

-------------------------------------------------------------------------------
CREATE APP
-------------------------------------------------------------------------------

cd $CRATE_DJANGO_ROOT
$CRATE_MANAGE startapp research
# now add it to INSTALLED_APPS in settings.py

-------------------------------------------------------------------------------
EXPLORE APP FROM COMMAND LINE
-------------------------------------------------------------------------------

$CRATE_MANAGE shell
# See https://docs.djangoproject.com/en/1.8/intro/tutorial01/

-------------------------------------------------------------------------------
CREATE SUPERUSER
-------------------------------------------------------------------------------

$CRATE_MANAGE createsuperuser

# Now run the demo server and go to http://127.0.0.1:8000/admin/

-------------------------------------------------------------------------------
TUTORIALS
-------------------------------------------------------------------------------

- https://docs.djangoproject.com/en/1.8/intro/tutorial01/
- https://www.youtube.com/watch?v=oT1A1KKf0SI&amp;list=PLxxA5z-8B2xk4szCgFmgonNcCboyNneMD&amp;index=1

-------------------------------------------------------------------------------
USER PROFILES
-------------------------------------------------------------------------------

# http://stackoverflow.com/questions/19433630/how-to-use-user-as-foreign-key-in-django-1-5
# https://docs.djangoproject.com/en/dev/topics/auth/customizing/#referencing-the-user-model
# https://www.youtube.com/watch?v=qLRxkStiaUg&amp;list=PLxxA5z-8B2xk4szCgFmgonNcCboyNneMD&amp;index=22

cd $CRATE_DJANGO_ROOT
$CRATE_MANAGE startapp userprofile
# edit settings.py (a) INSTALLED_APPS; (b) AUTH_PROFILE_MODULE = &#39;userprofile.UserProfile&#39;

-------------------------------------------------------------------------------
GENERAL DJANGO ADVICE
-------------------------------------------------------------------------------
Cheat sheet: http://www.mercurytide.co.uk/news/article/django-15-cheat-sheet/

Collected tips: http://stackoverflow.com/questions/550632/favorite-django-tips-features
... including:

    $CRATE_MANAGE graph_models -a -g -o crate_model_diagram.png

    $CRATE_MANAGE runserver_plus
    assert False somewhere; then use the Werkzeug console to explore

===============================================================================
CONSENT-MODE DATABASE
===============================================================================
- General principle to avoid storing BLOBs in databases, to keep the database
  small, and to allow static file serving. With Django, for private static
  files, that may need something like X-Sendfile:
    http://zacharyvoase.com/2009/09/08/sendfile/
    http://django-private-files.readthedocs.org/en/0.1.2/serverconf.html
    ... Apache with mod_xsendfile
    http://stackoverflow.com/questions/1156246/having-django-serve-downloadable-files
- However, we do want to concatenate PDFs to make packages for clinicians.
  Though not necessarily very often.
- Outbound e-mails can be stored as text (e.g. HTML).
- Letters could be stored as PDFs (e.g. files) or as the HTML used to generate
  the PDF (smaller; reproducible exactly unless e.g. the header changes).



If you drop a table, or want to drop a table:
    http://stackoverflow.com/questions/5328053/how-to-restore-dropped-table-with-django-south

===============================================================================
CSS MODEL
===============================================================================
- Static or template-based?
  Since we want consistency across web/email/PDF (inc. the web aspects of
  clinicians responding to e-mails), and since we have to embed CSS for email,
  we&#39;ll embed the lot and use templates.

- CSS selector tutorial:
  http://css.maxdesign.com.au/selectutorial/selectors_class.htm

===============================================================================
GENERAL DJANGO NOTES FOR URL/&#39;GET&#39; INFORMATION-PASSING:
===============================================================================
1. URL path
    - create in code with reverse()
    - encapsulate the output of reverse() in request.build_absolute_uri()
      to get an absolute URI with site domain name, etc.
    - details are read back by the urlconf regexes (in urls.py) and passed
      to views as parameters
    - validation is &quot;manual&quot; e.g. using
        study = get_object_or_404(Study, pk=study_id)
        if not custom_is_valid_function(extraparam):
            raise Http404(&#39;error message&#39;)
    - ... or could validate manually with a form, e.g.
        form = MyForm(request.GET, extraparam)
      using the style at
        http://stackoverflow.com/questions/18769607/django-form-with-customer-parameter-and-validation-not-getting-clean-function  # noqa

2. Query parameters
    - can encode using urllib, e.g.
        def url_with_querystring(path, **kwargs):
            return path + &#39;?&#39; + urllib.urlencode(kwargs)
    - ?BETTER is to encode using Django&#39;s QueryDict and its urlencode()
      method:
        q = QueryDict(mutable=True)
        q[&#39;key&#39;] = value
        querybits = q.urlencode()
    - read them like this:
        request.GET.get(&#39;key&#39;, &#39;defaultvalue&#39;)
    - or could read/validate them with a form and its validators:
        form = MyForm(request.GET):
        # ... might use a ChoiceField or other validators
        if form.is_valid():
            ...
        else:
            ...

3. Combining them
    &quot;{path}?{querystring}&quot;.format(
        path=request.build_absolute_uri(reverse(...)),
        querystring=querydict.urlencode()
    )
    ... etc ...

4. Which is best?
    - path parameters:
        best for fixed resource lookup
        elegant handling in Django; DRY
    - query parameters:
        best for display modification
        order can vary
        they can be optional
        form-based validation is simpler
    - sometimes either works

5. But if we&#39;re building a Django object...
    - consider a ModelForm
    - slide
        35 - basic pattern
        86 - unit testing
        99 - dynamically adding fields
      of http://www.slideshare.net/pydanny/advanced-django-forms-usage
      BUT SEE
        http://www.pydanny.com/the-easy-form-views-pattern-controversy.html
      ... use this:
        request.POST if request.method == &#39;POST&#39; else None
      not this:
        request.POST or None

http://stackoverflow.com/questions/2345708/how-can-i-get-the-full-absolute-url-with-domain-in-django  # noqa
http://stackoverflow.com/questions/150505/capturing-url-parameters-in-request-get  # noqa
http://stackoverflow.com/questions/2778247/how-do-i-construct-a-django-reverse-url-using-query-args  # noqa
http://whippleit.blogspot.co.uk/2010/10/pretty-urls-vs-query-strings.html
http://stackoverflow.com/questions/3821663/querystring-in-rest-resource-url
http://stackoverflow.com/questions/9399147/django-form-validation-with-get

===============================================================================
Back-end processing: Celery
===============================================================================
- High-end optimum broker for Celery is perhaps RabbitMQ.
  Can persist messages to disk (or say you don&#39;t care).
  But moderately complex.
- Simpler is Celery with the Django database backend as the broker.
  And we have a very low volume of traffic.

http://docs.celeryproject.org/en/latest/getting-started/brokers/django.html#broker-django

- pip install celery
- in Django settings.py
    BROKER_URL = &#39;django://&#39;
    CELERY_ACCEPT_CONTENT =  [&#39;json&#39;]
    CELERY_RESULT_SERIALIZER = &#39;json&#39;
    CELERY_TASK_SERIALIZER = &#39;json&#39;
    INSTALLED_APPS should include &#39;kombu.transport.django&#39;
- manage.py migrate
    ... will make tables djkombu_message, djkombu_queue
- follow http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html

- to run a debugging worker:
    cd .../crateweb
    celery -A consent worker --loglevel=debug

- NOTE difficulty with PYTHONPATH
    ... if PYTHONPATH includes .../crate and .../crate/crateweb,
    Django moans when you start about duplicate filesystem locations.
    ... if it only includes .../crate and you start Celery from a random
    location with &quot;crateweb.consent&quot; as the module name, it can&#39;t find
    other Django bits like &quot;userprofile&quot;.
    ... so the above seems simplest.
    ... and celery also says you have to:
        http://docs.celeryproject.org/en/latest/getting-started/next-steps.html#next-steps

- Anyway, success now.

- However, database is going to grow (old messages not pruned).
  Generally true? I&#39;m unclear; https://github.com/celery/kombu/issues/276

  Let&#39;s try RabbitMQ.

    sudo apt-get install rabbitmq-server
    # ... will autostart service

  Easy. Also, much snappier.

  Will start with localhost-only access via the &quot;guest&quot; account:
    https://www.rabbitmq.com/access-control.html

  Status:
    sudo rabbitmqctl status
    sudo rabbitmqctl report


===============================================================================
mod_wsgi-express, etc.
===============================================================================

# http://blog.dscpl.com.au/2015/04/introducing-modwsgi-express.html
# http://blog.dscpl.com.au/2015/04/using-modwsgi-express-with-django.html
# http://blog.dscpl.com.au/2015/04/integrating-modwsgi-express-as-django.html
# http://blog.dscpl.com.au/2015/05/using-modwsgi-express-as-development.html
# https://pypi.python.org/pypi/mod_wsgi
# https://gist.github.com/GrahamDumpleton/b79d336569054882679e

# https://opensourcemissions.wordpress.com/2010/03/12/finally-a-working-django-non-root-url-with-mod_wsgi/
# https://groups.google.com/forum/#!topic/django-users/xFdZnKq26H0
# https://code.djangoproject.com/ticket/8906

# http://stackoverflow.com/questions/30566836/how-to-autostart-apachectl-script-that-mod-wsgi-express-made-for-django

===============================================================================
Celery (etc.) as daemon, and overall stack
===============================================================================

Most convenient to use supervisor/django-supervisor?
    http://stackoverflow.com/questions/14275821/how-to-run-celery-as-a-daemon-in-production
Supervisor won&#39;t install via pip for Python 3. It&#39;s Python 2 only at present:
    http://supervisord.org
However, it is an Ubuntu package (supervisor).
Then we can use django-supervisor.
    ... or maybe not; the installation is difficult.

The &quot;raw&quot; Celery methods are:
    http://docs.celeryproject.org/en/latest/tutorials/daemonizing.html#daemonizing
    http://docs.celeryproject.org/en/latest/getting-started/next-steps.html#next-steps

Possibly just follow this, which is clear:
    http://www.apreche.net/complete-single-server-django-stack-tutorial/

supervisord / PYTHONPATH
    http://stackoverflow.com/questions/7930259/supervisor-running-a-python-script-pythonpath-issue

===============================================================================
Overall stack
===============================================================================

- We want very simple installation.
- Happy to mandate Ubuntu/Debian for now. (CentOS is a pain, for a start.)
- Several components of the stack auto-run (Apache; RabbitMQ).
- No pressing reason not to run &quot;proper&quot; Apache.
  Alternative include &quot;standalone&quot; Apache via mod_wsgi-express, which would
  need daemonizing; other similar Python-based servers like nginx/gunicorn
- If Apache is used, then that keeps the Django bit up and running.
- Only other bit that needs daemonizing is Celery; we can daemonize that with
  supervisord (which can be installed via Ubuntu).
  Once configured, this works beautifully.

  For monitoring, can use:
    sudo supervisorctl

- So installation process would be:

    sudo gdebi --non-interactive PACKAGE
    ... ensure Ubuntu requirements
        ... makes RabbitMQ happen automatically
        ... Apache configuration is the user&#39;s business (but we offer instructions)
    ... install code to /usr/share/crate
    ... create virtualenv in /usr/share/crate/virtualenv
        using sub-script install_virtualenv.sh
        parameters:
            (1) virtualenv: /usr/share/crate/virtualenv
            (2) secrets: /etc/crate
        ... ensure Python package requirements
        ... create specimen /etc/crate/crate_local_settings.py
        ... create customized instructions.txt for Apache, supervisord
    ... create some scripts in /usr/share/crate
        - launch demo Django server
        - launch debugging Celery backend
    ... restart supervisor
    ... restart Apache, if running

- The other possibility might be to run a separate web server and proxy it from Apache, e.g.
    http://stackoverflow.com/questions/6418016/gunicorn-via-mod-proxy-is-redirecting-outside-of-the-projects-scope-despite-pr
    http://serverfault.com/questions/429404/help-me-understand-how-to-use-proxypass
    http://blog.endpoint.com/2013/04/making-ssl-work-with-django-behind.html
  It adds another thing to fall over, but it would allow Apache to run without
  restarting even when Python apps need to be restarted (a positive...).
  Plus it would allow non-root running more simply, since port 80 is restricted.
  And it minimizes the amount of Apache configuration required from the end user.
  And it makes &quot;development versus production&quot; simpler.
  It also has the consequence that we don&#39;t have mod_wsgi tied to a specific
  Python version, which is a massive pain.
- OK. Let&#39;s give it a go with gunicorn.

    http://michal.karzynski.pl/blog/2013/06/09/django-nginx-gunicorn-virtualenv-supervisor/

Unix domain sockets

- Working
- However, Django debug toolbar stops working

    https://github.com/django-debug-toolbar/django-debug-toolbar/issues/690
    https://github.com/benoitc/gunicorn/issues/797

    ... see fix to INTERNAL_IPS, which is a bit bizarre, in the specimen
    config file.

SSL proxy

    https://bharatikunal.wordpress.com/2010/12/01/howto-reverseproxy-to-https-in-apache/





-------------------------------------------------------------------------------
NOT THE SIMPLEST: To use Apache with mod_wsgi
-------------------------------------------------------------------------------
# ... we&#39;ll skip this.

(a) Add Ubuntu prerequisites

    sudo apt-get install apache2 libapache2-mod-wsgi-py3 libapache2-mod-xsendfile

(b) Configure Apache for CRATE.
    Use a section like this in the Apache config file:

&lt;VirtualHost *:80&gt;
    # ...

    # =========================================================================
    # CRATE
    # =========================================================================

    # Define a process group (using the specimen name crate_pg)
    # Must use threads=1 (code may not be thread-safe).
    # Example here with 5 processes.
    WSGIDaemonProcess crate_pg processes=5 threads=1 python-path=$SITE_PACKAGES:$DEST_DJANGO_ROOT:$SECRETS_DIR

    # Point a particular URL to a particular WSGI script (using the specimen path /crate)
    WSGIScriptAlias /crate $DEST_DJANGO_ROOT/config/wsgi.py process-group=crate_pg

    # Redirect requests for static files, and admin static files.
    # MIND THE ORDER - more specific before less specific.
    Alias /static/admin/ $SITE_PACKAGES/django/contrib/admin/static/admin/
    # Alias /static/debug_toolbar/ $SITE_PACKAGES/debug_toolbar/static/debug_toolbar/
    Alias /static/ $DEST_DJANGO_ROOT/static/

    # Make our set of processes use a specific process group
    &lt;Location /crate&gt;
        WSGIProcessGroup crate_pg
    &lt;/Location&gt;

    # Allow access to the WSGI script
    &lt;Directory $DEST_DJANGO_ROOT/config&gt;
        &lt;Files &quot;wsgi.py&quot;&gt;
            Require all granted
        &lt;/Files&gt;
    &lt;/Directory&gt;

    # Allow access to the static files
    &lt;Directory $DEST_DJANGO_ROOT/static&gt;
        Require all granted
    &lt;/Directory&gt;

    # Allow access to the admin static files
    &lt;Directory $SITE_PACKAGES/django/contrib/admin/static/admin&gt;
        Require all granted
    &lt;/Directory&gt;

    # Allow access to the debug toolbar static files
    # &lt;Directory $SITE_PACKAGES/debug_toolbar/static/debug_toolbar&gt;
    #     Require all granted
    # &lt;/Directory&gt;

&lt;/VirtualHost&gt;

(c) Additionally, install mod_xsendfile, e.g. (on Ubuntu):

        sudo apt-get install libapache2-mod-xsendfile

    ... which will implicitly run &quot;a2enmod xsendfile&quot; to enable it. Then add to
    the Apache config file in an appropriate place:

        # Turn on XSendFile
        &lt;IfModule mod_xsendfile.c&gt;
            XSendFile on
            XSendFilePath /MY/SECRET/CRATE/FILE/ZONE
            # ... as configured in your secret crate_local_settings.py
        &lt;/IfModule&gt;

- If you get problems, check the log, typically /var/log/apache2/error.log
- If it&#39;s a permissions problem, check the www-data user can see the file:
    sudo -u www-data cat FILE
    # ... using an absolute path
    groups USER
- If Chrome fails to load GIFs and says &quot;pending&quot; in the Network developer
  view, restart Chrome. (Probably only a &quot;caching of failure&quot; during
  development!)

-------------------------------------------------------------------------------
Standalone Apache with mod_wsgi-express
-------------------------------------------------------------------------------

    pip install mod_wsgi-httpd  # a bit slow; don&#39;t worry
    pip install mod_wsgi

    mod_wsgi-express start-server config.wsgi \\
        --application-type module \\
        --log-to-terminal \\
        --port 80 \\
        --processes 5 \\
        --python-path $SECRETS_DIR \\
        --threads 1 \\
        --url-alias /static $DEST_DJANGO_ROOT/static \\
        --working-directory $DEST_DJANGO_ROOT

- This changes to the working directory and uses config/wsgi.py
- Add --reload-on-changes for debugging.
- Port 80 will require root privilege.


===============================================================================
Versioning
===============================================================================

versioning (think for CamCOPS and for consent mode)

https://www.djangopackages.com/grids/g/versioning/
    Python 3 support and production/stable -- narrows to
        Django Reversion
        django-simple-history
    ... of which Django Reversion looks best, as it can &quot;version&quot;
        relationships.

===============================================================================
Making the debug toolbar appear in different settings
===============================================================================

# If you want to use the Django debug toolbar while proxying (e.g. between
# gunicorn and Apache) through a Unix domain socket, this will wipe out
# REMOTE_ADDR, which is checked in debug_toolbar.middleware.show_toolbar .
# Bizarrely, while at first glance it looks like b&#39;&#39;, it&#39;s actually &quot;b&#39;&#39;&quot;!
# So you would need this:
#
# INTERNAL_IPS = (
#     &#39;127.0.0.1&#39;,  # for port proxy
#     &quot;b&#39;&#39;&quot;,  # for Unix domain socket proxy
# )
#
# An alternative is to set DEBUG_TOOLBAR_CONFIG as per
# http://stackoverflow.com/questions/28226940/django-debug-toolbar-wont-display-from-production-server  # noqa
# Like this:

def always_show_toolbar(request):
    return True # Always show toolbar, for example purposes only.

DEBUG_TOOLBAR_CONFIG = {
    &#39;SHOW_TOOLBAR_CALLBACK&#39;: always_show_toolbar,
}

===============================================================================
SQL Server
===============================================================================

http://stackoverflow.com/questions/13726670/using-jython-with-django

- Microsoft SQL Server drivers:
  OLD: ODBC: https://msdn.microsoft.com/en-us/library/hh568451(v=sql.110).aspx
  NEW: JDBC: https://www.microsoft.com/en-gb/download/details.aspx?id=11774
  OPEN SOURCE: jTDS: http://jtds.sourceforge.net/

- Django-Jython supports zxJDBC, which supports SQL Server via jTDS:
  https://pythonhosted.org/django-jython/database-backends.html
  # &#39;ENGINE&#39;: &#39;doj.db.backends.mssql&#39;,

- Jython is Python in a JVM. It&#39;s not clear this is very easy to set up with Apache.
  https://www.mail-archive.com/pythonireland@googlegroups.com/msg00945.html

- Django (Python) support Microsoft SQL Server via django-mssql, but that is Windows only, and doesn&#39;t support Linux.
  http://django-mssql.readthedocs.org/en/latest/
  http://stackoverflow.com/questions/22604732/linux-django-sqlserver

- Another Python route, looking dated:
  Django / django-sqlserver / python-tds
  https://github.com/denisenkom/django-sqlserver  # BECOMING OUT OF DATE? SAYS IT CAN&#39;T HANDLE DATETIME COLUMNS PROPERLY.
  # django-sqlserver was formerly called django-pytds
  # OLD # https://bitbucket.org/denisenkom/django-pytds
  https://pypi.python.org/pypi/python-tds

  http://python-tds.readthedocs.org/en/latest/

- Another Python route, looking more recent:
  Django / django-pymssql / pymssql / [?FreeTDS]
  https://github.com/aaugustin/django-pymssql
  http://www.pymssql.org/en/latest/

- Another Python route, but not Python 3:
  Django / django-pyodbc
  https://github.com/lionheart/django-pyodbc/
  http://stackoverflow.com/questions/24026608/sql-server-2008-2012-backend-module-for-django-on-linux
  http://stackoverflow.com/questions/2791766/django-pyodbc-sql-server-freetds-server-connection-problems-on-linux

TO READ:
http://blog.nguyenvq.com/blog/tag/jtds/


LIKELY BEST? AVOID JAVA. And jaydebeapi is a bit flaky, and doesn&#39;t integrate with Django as yet.

Django / django-pyodbc-azure / pyodbc / UnixODBC / FreeTDS
  http://stefanoapostolico.com/2015/04/20/django_mssql_osx.html
  https://github.com/michiya/django-pyodbc-azure
  https://github.com/mkleehammer/pyodbc
  http://www.unixodbc.org/
  http://www.freetds.org/

  +/- https://code.google.com/p/django-pyodbc/wiki/FreeTDS
  +/- http://stackoverflow.com/questions/24906016/exception-value-08001-08001-unixodbcfreetdssql-serverunable-to-con
  and http://stackoverflow.com/questions/20283199/django-pyodbc-azure-databaseerror-42000-42000-error-converting-data-type
  ... = how to set TDS protocol version with Django

... NB not old UnixODBC versions: https://github.com/michiya/django-pyodbc-azure/issues/4


SUMMARY: From Django onwards through the stack:

    django-jython
        zxJDBC
            jTDS
    django-mssql
        quasi-endorsed by Django but FAIL: needs Windows
    django-sqlserver
        POSSIBLE? django-sqlserver==1.7 -- BUGGY; tries to import &quot;django.db.backends.util&quot; (should be &quot;utils&quot;) with Django 1.9rc1
    django-pyodbc-azure


-------------------------------------------------------------------------------
django-pyodbc-azure -&gt; unixODBC -&gt; FreeTDS -&gt; SQL Server
-------------------------------------------------------------------------------
- https://github.com/michiya/django-pyodbc-azure/blob/azure/README.rst

1. On the Windows end (in this case, 192.168.1.13):

    (*) SQL Server Configuration Manager (from Windows Start menu)
        &gt; SQL Server 2005 Network Configuration
        &gt; Protocols for MSSQLSERVER
        &gt; TCP/IP
        &gt; Enabled (and double-click &quot;TCP/IP&quot; for more settings)

    (*) Create a database in Microsoft SQL Server Management Studio Express.
        e.g. crate_sqlserver_db

    (*) Create a user:
        Microsoft SQL Server Management Studio Express
        &gt; [root server, e.g. WOMBATVMXP]
        &gt; Security
        &gt; Logins
        &gt; (right-click: Add Login)
        &gt;   Login name = crate_user
            SQL Server authentication
                password = something
            set sensible defaults like not requiring password change

    (*) Allow the user access
        Microsoft SQL Server Management Studio Express
        &gt; New Query [button]
            USE crate_sqlserver_db;
            -- NOT SURE -- EXEC sp_grantdbaccess crate_user;
            -- DOESN&#39;T DO MUCH -- GRANT ALL TO crate_user;
            EXEC sp_addrolemember &#39;db_owner&#39;, &#39;crate_user&#39;;

    (*) Allow proper logins via TCP/IP:
        Microsoft SQL Server Management Studio Express
        &gt; [root server, e.g. WOMBATVMXP]
        &gt; Security
        &gt; Logins
        &gt; (right-click: Properties)
        &gt; Security
            Server authentication = SQL Server and Windows Authentication mode

    (*) Services &gt; stop/restart &quot;SQL Server (MSSQLSERVER)&quot;

    (*) netstat -a
        ... to verify port 1433 is open (or &quot;ms-sql-s&quot;)

    (*) from another machine, check the port is open:
        telnet 192.168.1.13 1433

    OK. Back to the Linux end.

2. Get latest FreeTDS (see also http://www.freetds.org/)

    $ sudo apt-get install freetds-bin tdsodbc

    ... note that tdsodbc is critical for /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so

3. Test the FreeTDS connection

    $ TDSVER=8.0 tsql -H 192.168.1.13 -p 1433 -U crate_user -P something

    Failure levels:
        &quot;No route to host&quot;
        &quot;Connection refused&quot;
            -- duff port or port not open
        &quot;Login failed for user &#39;&#39;. The user is not associated with a trusted
        SQL Server connection.&quot; / &quot;Adaptive Server connection failed&quot;
            -- better... need to allow TCP/IP access
        &quot;Cannot open user default database. Using master database instead.&quot;
            -- much better; need the grant command as above
    At the point of success:
        locale is &quot;en_GB.UTF-8&quot;
        locale charset is &quot;UTF-8&quot;
        using default charset &quot;UTF-8&quot;
        1&gt;

    Then:
        1&gt; SELECT * FROM notes
        2&gt; GO
    Also:
        &gt; VERSION
        ... to show TDS protocol version
    Which version? Choose from
        http://www.freetds.org/userguide/choosingtdsprotocol.htm
    ... but if you get &quot;unrecognized msgno&quot;, go up.

4. Get unixODBC and nice tools

    $ sudo apt-get install unixodbc-bin

5. Configure ODBC

    - ignore /etc/freetds/freetds.conf
        ... though there are some optional [global] settings there

    - in /etc/odbcinst.ini

        [FreeTDS]
        Description = FreeTDS (SQL Server protocol driver for Unix)
        Driver = /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so
        Setup = /usr/lib/x86_64-linux-gnu/odbc/libtdsS.so

    - in /etc/odbc.ini, or ~/.odbc.ini

        [crate_sqlserver_odbc]
        description = &quot;CRATE test SQL Server 2005 database on Wombat VMXP&quot;
        driver = FreeTDS
        TDS_Version = 8.0
        ; which TDS version setting is read, of the several possibilities? See http://stackoverflow.com/questions/13066716
        server = 192.168.1.13
        port = 1433

    $ odbcinst -j  # print config information
    $ odbcinst -q -d  # query drivers
    $ odbcinst -q -s  # query data sources
    $ ODBCManageDataSourcesQ4  # visual confirmation of everything

6. Configure Django

    - in settings.py:

        &#39;research&#39;: {
            &#39;ENGINE&#39;: &#39;sql_server.pyodbc&#39;,
            &#39;NAME&#39;: &#39;crate_sqlserver_db&#39;,
            &#39;USER&#39;: &#39;crate_user&#39;,
            &#39;PASSWORD&#39;: &#39;something&#39;,
            &#39;OPTIONS&#39;: {
                &#39;dsn&#39;: &#39;crate_sqlserver_odbc&#39;,
            }
        },

    - should then work.
</pre></div>
</div>
</div>
<div class="section" id="notes-on-database-schemas-txt">
<h2>12.9. notes_on_database_schemas.txt<a class="headerlink" href="#notes-on-database-schemas-txt" title="Permalink to this headline">¶</a></h2>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>===============================================================================
Microsoft SQL Server
===============================================================================

In Microsoft SQL Server (MSSQL), at least from 2005+, there are 4 &quot;layers&quot;:

    SELECT database_name.schema_name.table_name.column_name
    FROM database_name.schema_name.table_name;

The default schema is &#39;dbo&#39;.
(In old versions of MSSQL, up to SQL Server 2000, &quot;owners&quot; stood in the stead
of schemas; the default owner was &#39;dbo&#39;, the database owner.)

- https://technet.microsoft.com/en-us/library/dd283095(v=sql.100).aspx
- https://blog.sqlauthority.com/2009/09/07/sql-server-importance-of-database-schemas-in-sql-server/

Default schemas include:
    dbo
    guest
    sys
    INFORMATION_SCHEMA

... so there&#39;s one of those for EACH database.

- https://msdn.microsoft.com/en-us/library/bb669061(v=vs.110).aspx

Can a connection talk to &gt;1 database? Yes.
A connection has a database context.
This is set automatically to the default database for the login, and can be
set or changed explicitly using
    USE mydatabase;

- https://msdn.microsoft.com/en-us/library/ms188366.aspx

SELECTed things can actually be 5-layered; the &quot;table&quot;-level one can be any
of:

    server_name.[database_name].[schema_name].object_name
    | database_name.[schema_name].object_name
    | schema_name.object_name
    | object_name

- https://msdn.microsoft.com/en-us/library/ms177563.aspx

To describe a database, use its INFORMATION_SCHEMA.

===============================================================================
PostgreSQL
===============================================================================

Similar to SQL Server in that the levels are database/schema/table/column.

However, Postgres doesn&#39;t allow you to query across databases, so &quot;schema&quot;
becomes more important.

- http://stackoverflow.com/questions/1152405/postgresql-is-it-better-using-multiple-databases-with-1-schema-each-or-1-datab
- http://stackoverflow.com/questions/46324/possible-to-perform-cross-database-queries-with-postgres
- http://stackoverflow.com/questions/4678862/joining-results-from-two-separate-databases
- http://wiki.postgresql.org/wiki/FAQ#How_do_I_perform_queries_using_multiple_databases.3F

The default PostgreSQL schema is &#39;public&#39;.

- https://www.postgresql.org/docs/9.3/static/ddl-schemas.html


===============================================================================
ANSI SQL
===============================================================================

- http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt
  21.2   INFORMATION_SCHEMA
  21.3.4 INFORMATION_SCHEMA.SCHEMATA

===============================================================================
MySQL
===============================================================================

SCHEMA and DATABASE are synonymous.

- http://stackoverflow.com/questions/11618277/difference-between-schema-database-in-mysql
- https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_schema

The SELECT statement can go up to:

    SELECT database_name.table_name.column_name
    FROM database_name.table_name;

As before, the USE statement allows you to specify a particular default
database, but doesn&#39;t stop you querying from others.

- https://dev.mysql.com/doc/refman/5.7/en/use.html

INFORMATION_SCHEMA is at the same level as databases.
... and the TABLE_CATALOG column is meaningless.

See als:
- http://dba.stackexchange.com/questions/3774/what-is-the-point-of-the-table-catalog-column-in-information-schema-tables

===============================================================================
CRATE web interface
===============================================================================

- We will have a single connection to the research database(s).
- That is django.conf.settings.DATABASES[&#39;research&#39;].
- We will want to scan, potentially, several schemas.
- We don&#39;t want a distinction between the &quot;browse structure&quot; views and the
  query builder.
- We&#39;ll need to know the dialect, to know whether we need to use d.s.t.c
  or a three-level structure.
- For MySQL, should we call the top level &quot;database&quot; or &quot;schema&quot;?
- Well, the concept of schemas allows enforced foreign keys between two
  different schemas in the same database (in SQL Server).
  - http://stackoverflow.com/questions/2095268/foreign-key-reference-to-table-in-another-schema
- SQL Server doesn&#39;t allow referential constraints across databases, except
  via manual triggers
  - http://stackoverflow.com/questions/4452132/add-foreign-key-relationship-between-two-databases
- What about MySQL?
  MySQL allows FKs between two different databases, I think:
  - http://stackoverflow.com/questions/3905013/mysql-innodb-foreign-key-between-different-databases
  ... but are they properly enforced? I think so.
- That would make a MySQL {database/schema} more like an SQL Server schema,
  rather than an SQL Server database.
- On the other hand, from the outside in, &quot;database&quot; probably makes more sense
  to users.

- Therefore, we&#39;ll say that RESEARCH_DB_INFO has keys:
    database  -- None for MySQL/PostgreSQL
    schemas
    ...

- The query builder may or may not offer the additional &quot;database&quot; level.
</pre></div>
</div>
</div>
<div class="section" id="old-notes-txt">
<h2>12.10. old notes.txt<a class="headerlink" href="#old-notes-txt" title="Permalink to this headline">¶</a></h2>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>===============================================================================
Considered but not implemented
===============================================================================

- NOT YET SUITABLE FOR PYTHON 3: the following dependencies do not work:
    docx (in rnc_extract_text.py)

- Ability to run an incremental update from a partial data set.
  Since this data set might not include all identifiers, the software would
  have to store the anonymisation information (e.g. a repr()-style
  representation of the regexes) and work on the assumption that identifiers
  can be added but not subtracted. However, this is still problematic: if
  a scrubber has changed, the rows it&#39;s scrubbed should be re-scrubbed, but
  that requires the original data source (unless one were just to re-scrub
  the destination from its previous version, which would give potentially
  inconsistent results). So not implemented.

===============================================================================
Performance
===============================================================================

    For a test source database mostly consisting of text (see makedata.py),
    on a 8-core x 3.5-Ghz machine, including (non-full-text) indexing:

from __future__ import division
test_size_mb = 1887
time_s = 84
speed_mb_per_s = test_size_mb / time_s
cpft_size_gb = 84
estimated_cpft_time_min = cpft_size_gb * 1024 * time_s / (test_size_mb * 60)

    Initial speed tests (Mb/s):
        7.9 Mb/s with 1 process, 8 threads
        8.6 Mb/s with 1 process, 16 threads
        18.0 Mb/s with 8 patient processes + 1 for non-patient tables.
        18.0 Mb/s with 16 patient processes + 1 for non-patient tables.
    Most recent:
        22.5 Mb/s with 8 patient processes + 1 for non-patient tables.
    See launch_multiprocess.sh.
    Guesstimate for Feb 2015 CPFT RiO database (about 84 Gb): 1 h 04 min.
    Note that the full-text indexing is very slow, and would be extra.

Incremental updates:

    Where a full run takes 126s, an incremental run with nothing to do takes
    11s.

MySQL full-text indexing:

    http://dev.mysql.com/doc/refman/5.0/en/fulltext-search.html

    Once indexed, change this conventional SQL:
        SELECT something
        WHERE field1 LIKE &#39;%word%&#39; OR field2 LIKE &#39;%word%&#39;;

    to one of these:
        SELECT something
        WHERE MATCH(field1, field2) AGAINST (&#39;word&#39;);

        SELECT something
        WHERE MATCH(field1, field2) AGAINST (&#39;word&#39;);

    ... and there are some more subtle options.

    Improves speed from e.g.:
        SELECT brcid FROM notes WHERE note LIKE &#39;%Citibank%&#39;;
        ... 10.66 s
    to:
        SELECT brcid FROM idxnotes WHERE MATCH(note) AGAINST(&#39;citibank&#39;);
        ...  0.49 s

    NOTE: requires MySQL 5.6 to use FULLTEXT indexes with InnoDB tables (as
    opposed to MyISAM tables, which don&#39;t support transactions).

    On Ubuntu 14.04, default MySQL is 5.5, so use:
        sudo apt-get install mysql-server-5.6 mysql-server-core-5.6 \
            mysql-client-5.6 mysql-client-core-5.6
    ... but it does break dependences on (e.g.) mysql-server, so not yet done.


===============================================================================
Profiling
===============================================================================

python -m cProfile -s cumtime tools/launch_cherrypy_server.py &gt; ~/tmp/profile.txt

===============================================================================
Encryption/hashing
===============================================================================

- A normal PID might be an &#39;M&#39; number, RiO number, or some other such system-
  specific ID number. A master PID might be an NHS number.
- There must not be collisions in the PID -&gt; RID mapping; we need to keep our
  patients separate.
- The transformation must involve something unknown outside this (open-
  source) code. If we used encrypted = hashlib.sha256(plaintext).hexdigest(),
  then anybody could run that function over a bunch of integers from 0 to
  9,999,999,999 and they&#39;d have a simple way of reversing the algorithm for
  all PIDs up to that value.
- So the options are
  (a) hash with a secret salt;
  (b) hash with a random salt;
  (c) encrypt with a secret key.
- We can&#39;t use (b), because we want consistency in our PID -&gt; RID mappings
  when we we re-run the anonymisation.
- We do need to reverse one or both transformations, for consent-to-contact
  methods (and potentially clinicaly use), but only a superuser/research
  database manager should be able to do this.
- Thus, if we hash with a secret salt, we&#39;d have to store the PID/RID mapping
  somewhere safe.
- If we encrypt, we can skip that storage and just keep the secret key.
- We also want a consistent output length.
- With encryption, if the key is leaked, everything encrypted with it is
  available to those with access to the encrypted data. With a secret
  constant salt, the same is true (given a dictionary attack, since the stuff
  being encrypted is just a bunch of integers).
- This is *not* the same problem as password storage, where we don&#39;t care if
  two users have the same passwords. Here, we need to distinguish patients
  by the RID. It may be acceptable to use a per-patient salt, and then store
  the PID/RID mapping, but for an incremental update one would have to rely
  on being able to retrieve the old PID/RID mapping, or the mapping would
  change. So: per-patient salt wouldn&#39;t be safe for incremental updates.
- We&#39;re left with (a) and (c). Both are in principle vulnerable to loss of
  the secret information; but that will always be true of a reversible
  system.
- One benefit of encryption, is that we could use public-key encryption and
  this program would then never need to know the decryption key (whereas with
  a hash, it needs to know the salt, so loss of this program&#39;s config file
  will be of concern). The decryption key can be stored somewhere especially
  secret. However, RSA (for example) produces long output, e.g. 1024 bytes.
- Remaining options then include:
  (a) SHA256 hash with secret salt;
  (c) AES256 encryption with secret key.
  I don&#39;t think either has a strong advantage over the other, so since we do
  have to be able to reverse the system, we might as well use AES256. But
  then... AES should really have a random initialization vector (IV) used
  (typically stored with the encrypted output, which is fine), but that means
  that a second encryption of the same thing (e.g. for a second anonymisation
  run) gives a different output.
- If we want to use hex encoding and end up with an encrypted thing of length
  32 bytes, then the actual pre-hex value needs to be 16 bytes, etc.
- Anyway, pragmatic weakening of security for practical purposes: let&#39;s use
  an MD5 hash with a secret salt.

===============================================================================
NOT YET IMPLEMENTED
===============================================================================

- Incremental updates following small data dictionary changes, e.g. field
  addition. Currently, these require a full re-run.

===============================================================================
Z. NOTES
===============================================================================

-------------------------------------------------------------------------------
Q.  Segmentation fault (core dumped)... ?
-------------------------------------------------------------------------------
A.  Short answer: use the Microsoft JDBC driver instead of the Microsoft ODBC
    driver for Linux, which is buggy.

    Long answer, i.e. working this out:

    Examine the core with gdb anonymise.py ~/core
    ... then it tells you which program generated the core
    ... then gdb PROGRAM ~/core
    ... but actually the likely reason is being out of RAM
    ... monitor memory use with
            htop
            top (press M)
            watch free -m
                http://www.linuxatemyram.com/
    ... tried: reduce the innodb_thread_concurrency variable as above, and
        restart MySQL (under Ubuntu/Debian, with: sudo service mysql restart).
        - didn&#39;t fix it
    ... for 32M max_allowed_packet, use 320M (not 512M) for the logfile
        - did significantly reduce memory usage, but still crashed, and not
          while processing a large record
        - longest BLOB in this data set is
    So, systematic method:
    (1) What&#39;s the biggest packet needed? Estimate with:
            SELECT MAX(LEN(giantbinaryfield)) FROM relevanttable;
        ... in our case (CRS/CDL test): 39,294,299 = 37.47 MiB.
        So with a bit of margin, let&#39;s use
            max_allowed_packet = 40M
            innodb_log_file_size = 400M
    (2) Then set max number of rows and bytes, e.g. to 1000 rows and 80 MiB.
    OK, actually relates to a single specific record -- found using MySQL
    log with
            SET GLOBAL general_log = &#39;ON&#39;;
            SHOW VARIABLES LIKE &#39;general_log_file&#39;;
    ... but actually not relating to insertion at all, but to retrieval
    ... nrows=90060 then crash in gen_rows at the point of cursor.fetchone()
    ... This?
        http://stackoverflow.com/questions/11657958
        https://code.google.com/p/pyodbc/issues/detail?id=346
        https://msdn.microsoft.com/en-us/library/hh568448.aspx
        https://code.google.com/p/pyodbc/issues/detail?id=188
    ... changing rnc_db to use pypyodbc rather than pyodbc:
            sudo pip install pypyodbc
            import pypyodbc as pyodbc
        ... crashed at the same point (segfault).
        ... so back to pyodbc
    ... git clone https://github.com/mkleehammer/pyodbc
        ... getdata.cpp, as one bughunt above suggested, already has that fix
    ... sudo pip install pyodbc --upgrade  # from 3.0.6 to 3.0.7
        ... no change
    ... try the query using Perl and DBI::ODBC -- also crashes.
        So probably a bug in the SQL Server Native Client 11.0 for Linux.
    ... can&#39;t use FreeTDS because the SQL Server won&#39;t let us login (another
        Microsoft bug).
    ... removing the VARCHAR(MAX) fields from the data dictionary makes it happy again.
    ... random: http://www.saltycrane.com/blog/2011/09/notes-sqlalchemy-w-pyodbc-freetds-ubuntu/

    [Full details in private log.]

    Switched to the JDBC driver.
    Problem went away.


-------------------------------------------------------------------------------
Q.  &quot;Killed.&quot;
-------------------------------------------------------------------------------
A.  Out of memory.
    Suggest
    - Reduce MySQL memory footprint; see notes below.
    Testing on a rather small machine (0.5 Gb RAM, 1 Gb swap).
    Inspect what was running:

        # cat /var/log/syslog

    Remove memory-hogging things:

        # apt-get purge modemmanager
        - change the report_crashes parameter to false in the /etc/default/whoopsie file.
        # service whoopsie stop
        # apt-get remove unity unity-asset-pool unity-control-center unity-control-center-signon unity-gtk-module-common unity-lens* unity-services unity-settings-daemon unity-webapps* unity-voice-service
        ... NOT YET REMOVED: network-manager

    Inspect it:

        # pmap -x &lt;process_id&gt;

    Leaks?
    - http://www.lshift.net/blog/2008/11/14/tracing-python-memory-leaks/

        $ python -m pdb ./anonymise.py
        (Pdb) run crs_cdl_anon.ini -v
        (Pdb) c

    Use openDBcopy to copy the database: http://opendbcopy.sourceforge.net/

        Prerequisites
            export JAVA_HOME=/usr/lib/jvm/default-java
            cd ~/openDBcopy/bin
            ./start.sh &amp;

        Plugin chain:

            - Migrate database schema (DDL)

                0.  Configuration

                1.  Database connections
                    SOURCE
                        Driver name = Microsoft MSSQL Server JDBC Driver
                        Driver class = com.microsoft.sqlserver.jdbc.SQLServerDriver
                        URL = jdbc:sqlserver://XXX:1433;databaseName=XXX
                        User name = XXX
                        Password = XXX
                    DESTINATION
                        Driver name = MySQL Driver
                        Driver class = com.mysql.jdbc.Driver
                        URL = jdbc:mysql://localhost:3306/DATABASENAME
                        User name = XXX
                        Password = XXX
                    TEST BOTH.

                2.  Source model
                        Catalog = [DATABASE NAME]
                        Schema = dbo
                        Table pattern = %
                    CAPTURE SOURCE MODEL.

                3.  Tables to migrate
                        = all by default

                4.  Columns to migrate
                        = all by default

            - Copy data from a source into a destination database

        ... NOT WORKING.

    - http://stackoverflow.com/questions/27068092/jpype-java-initialize-with-or-get-remaining-heap-space

    - http://stackoverflow.com/questions/1178736/mysql-maximum-memory-usage
    - SHOW ENGINE INNODB STATUS

    USEFUL THINGS:
    - see estimate_mysql_memory_usage.sh
    - changed innodb_buffer_pool_size from 128M to 16M
        ... big improvement; mysqld %MEM (in top) went from ~30% to ~10%
    - RTF processing takes lots of memory, using Python/pyth
        ... significant improvement after switching to Linux/unrtf
        ... similarly, using Linux/pdftotext rather than Python/pdfminer

    AFTERWARDS:
    - Show table size and number of rows in MySQL (note: APPROXIMATE):

        SELECT table_name AS &#39;Table&#39;,
            ROUND(((data_length + index_length) / 1024 / 1024), 2) AS &quot;Size in MiB&quot;,
            table_rows AS &#39;Approx. # rows&#39;
        FROM information_schema.TABLES
        WHERE table_schema = DATABASE()
        ORDER BY table_name;

    TEMPORARY HOLDUP: not enough disk space (~9.2 Gb on CPFT test machine):

        +---------------------+-------------+------------+
        | Table               | Size in MiB | table_rows |
        +---------------------+-------------+------------+
        | address             |       63.61 |     431262 |
        | alias               |        5.52 |      58468 |
        | assessment          |      256.63 |       9725 |
        | careplan            |      191.64 |      16801 |
        | careplangoal        |       98.64 |     187922 |
        | cdlinternalreferral |        2.52 |       4679 |
        | cdlpatient          |        2.52 |      14014 |
        | cgas                |        1.52 |       2571 |
        | dependant           |        0.13 |       1001 |
        | diagnosis           |        8.52 |      76361 |
        | documentlibrary     |     3795.00 |     474874 |
        | employment_status   |        0.02 |          0 |
        | exclude             |        0.02 |          0 |
        | honos               |        0.02 |          0 |
        | honos_65            |        0.02 |          0 |
        | honos_ca            |        0.02 |          0 |
        | honos_ld            |        0.02 |          0 |
        | honos_secure        |        0.02 |          0 |
        | living_arrangements |        0.02 |          0 |
        | mpi                 |        0.02 |          0 |
        | personal_carers     |        0.02 |          0 |
        | practicegp          |        0.02 |          0 |
        | procedures          |        0.02 |          0 |
        | referral            |        0.02 |          0 |
        | schedules           |        0.02 |          0 |
        | team_episodes       |        0.02 |          0 |
        | telephone           |        0.02 |          0 |
        | ward_stays          |        0.02 |          0 |
        +---------------------+-------------+------------+
        28 rows in set (0.42 sec)

        ... THEN OUT OF DISK SPACE:

        _mysql_exceptions.OperationalError: (1114, &quot;The table &#39;documentlibrary&#39; is full&quot;)

        Since we want to test with all patients being processed but only a
        subset of documents (to make sure all documents are anonymised), let&#39;s
        add the debug_row_limit and debug_limited_tables options in the config.

    Source (NB exact number of rows):

    2015-04-25 20:44:05.676:INFO:anonymise:crs_cdl_network.address: 394511 records
    2015-04-25 20:44:05.701:INFO:anonymise:crs_cdl_network.alias: 58606 records
    2015-04-25 20:44:05.722:INFO:anonymise:crs_cdl_network.assessment: 10874 records
    2015-04-25 20:44:05.762:INFO:anonymise:crs_cdl_network.careplan: 17601 records
    2015-04-25 20:44:05.820:INFO:anonymise:crs_cdl_network.careplangoal: 203553 records
    2015-04-25 20:44:05.851:INFO:anonymise:crs_cdl_network.cdlinternalreferral: 5098 records
    2015-04-25 20:44:05.869:INFO:anonymise:crs_cdl_network.cdlpatient: 13021 records
    2015-04-25 20:44:05.878:INFO:anonymise:crs_cdl_network.cgas: 2523 records
    2015-04-25 20:44:05.892:INFO:anonymise:crs_cdl_network.dependant: 953 records
    2015-04-25 20:44:05.922:INFO:anonymise:crs_cdl_network.diagnosis: 74119 records
    2015-04-25 20:44:06.075:INFO:anonymise:crs_cdl_network.documentlibrary: 691360 records
    2015-04-25 20:44:06.081:INFO:anonymise:crs_cdl_network.employment_status: 11874 records
    2015-04-25 20:44:06.093:INFO:anonymise:crs_cdl_network.honos: 16530 records
    2015-04-25 20:44:06.098:INFO:anonymise:crs_cdl_network.honos_65: 11948 records
    2015-04-25 20:44:06.112:INFO:anonymise:crs_cdl_network.honos_ca: 48 records
    2015-04-25 20:44:06.140:INFO:anonymise:crs_cdl_network.honos_ld: 866 records
    2015-04-25 20:44:06.151:INFO:anonymise:crs_cdl_network.honos_secure: 308 records
    2015-04-25 20:44:06.164:INFO:anonymise:crs_cdl_network.living_arrangements: 676 records
    2015-04-25 20:44:06.200:INFO:anonymise:crs_cdl_network.mpi: 159506 records
    2015-04-25 20:44:06.216:INFO:anonymise:crs_cdl_network.personal_carers: 37788 records
    2015-04-25 20:44:06.284:INFO:anonymise:crs_cdl_network.practicegp: 350050 records
    2015-04-25 20:44:06.292:INFO:anonymise:crs_cdl_network.procedures: 2688 records
    2015-04-25 20:44:06.376:INFO:anonymise:crs_cdl_network.referral: 353714 records
    2015-04-25 20:44:06.983:INFO:anonymise:crs_cdl_network.schedules: 2948420 records
    2015-04-25 20:44:07.028:INFO:anonymise:crs_cdl_network.team_episodes: 151836 records
    2015-04-25 20:44:07.064:INFO:anonymise:crs_cdl_network.telephone: 148720 records
    2015-04-25 20:44:07.097:INFO:anonymise:crs_cdl_network.ward_stays: 131985 records

    After phase 1 of copying/text extraction, with a 1000-row limit on the
    documentlibrary table (NB approximate number of rows):

    +---------------------+-------------+----------------+
    | Table               | Size in MiB | Approx. # rows |
    +---------------------+-------------+----------------+
    | address             |       70.13 |         425752 |
    | alias               |        7.03 |          59073 |
    | assessment          |      256.83 |          10318 |
    | careplan            |      191.95 |          20559 |
    | careplangoal        |      102.16 |         192640 |
    | cdlinternalreferral |        2.63 |           4741 |
    | cdlpatient          |        2.75 |          13209 |
    | cgas                |        1.59 |           2505 |
    | dependant           |        0.14 |            886 |
    | diagnosis           |       10.03 |          75277 |
    | documentlibrary     |        8.56 |           1274 |
    | employment_status   |        1.73 |          11945 |
    | exclude             |        0.02 |              0 |
    | honos               |        9.81 |          16171 |
    | honos_65            |        5.73 |          11701 |
    | honos_ca            |        0.06 |             63 |
    | honos_ld            |        0.50 |            912 |
    | honos_secure        |        0.23 |            309 |
    | living_arrangements |        0.11 |            588 |
    | mpi                 |       28.08 |         160866 |
    | personal_carers     |        7.03 |          38366 |
    | practicegp          |       80.13 |         354670 |
    | procedures          |        0.44 |           2225 |
    | referral            |      109.17 |         357245 |
    | schedules           |      990.59 |        2952553 |
    | team_episodes       |       35.08 |         151676 |
    | telephone           |       17.03 |         149018 |
    | ward_stays          |       29.08 |         131564 |
    +---------------------+-------------+----------------+


-------------------------------------------------------------------------------
Q.  Crash when closing cursor after reading VARBINARY(MAX) field (via SQL
    Server JDBC interface, via jpype, via jaydebeapi).
-------------------------------------------------------------------------------
A.  Short answer: fixed internally (in rnc_db.py) by reconfiguring the SQL
    Server JDBC connection.

    Long answer/thoughts:

    ps aux
    gdb -p 28896
    backtrace

        #0  0x00007fbfd1b3f14b in __libc_recv (fd=21, buf=0x7fff06f5a300, n=8,
            flags=-1) at ../sysdeps/unix/sysv/linux/x86_64/recv.c:33
        #1  0x00007fbfc09ece1d in ?? ()
           from /usr/lib/jvm/java-7-openjdk-amd64/jre/lib/amd64/libnet.so
        #2  0x00007fbfc09e8bd0 in Java_java_net_SocketInputStream_socketRead0 ()
           from /usr/lib/jvm/java-7-openjdk-amd64/jre/lib/amd64/libnet.so
        #3  0x00007fbfc10989a1 in ?? ()
        #4  0x0000000000000000 in ?? ()

    Related to this bug?
        https://bugs.openjdk.java.net/browse/JDK-8049846

    Occurs when you call cursor.close() of jaydebeapi:
        https://github.com/baztian/jaydebeapi/blob/master/jaydebeapi/__init__.py

    Unrelated to any conversion that I was doing.

    sudo apt-get remove openjdk-7-jre  # though didn&#39;t get rid of java

    sudo add-apt-repository ppa:webupd8team/java
    sudo apt-get update
    sudo apt-get install oracle-java8-installer

    ... no help

    Thoughts:
        https://code.google.com/p/jyjdbc/source/browse/jyjdbc/__init__.py
        https://social.technet.microsoft.com/Forums/en-US/430b4352-92c9-4a5c-98b5-f96643009453/jdbc-driver-thread-stuck-infinite-while-closing-result-set-locked?forum=sqldataaccess
        https://bugs.mysql.com/bug.php?id=74739

    Nasty workaround:
        don&#39;t close the cursors; use a set for each database?
        ... didn&#39;t help: crashed on the table *after* the one with the
        VARBINARY(MAX) field.

    SQL Server / JDBC driver / connection properties:
        https://msdn.microsoft.com/en-us/library/ms378672(v=sql.110).aspx
    ... and data types:
        https://msdn.microsoft.com/en-us/library/ms378813(v=sql.110).aspx

    FIXED!
        Use responseBuffering = adaptive in the settings for the SQL Server
        JDBC driver.
        https://msdn.microsoft.com/en-us/library/ms378988(SQL.90).aspx

    ---------------------------------------------------------------------------
    Enabling JDBC logging
    ---------------------------------------------------------------------------
        https://msdn.microsoft.com/en-us/library/ms378517(v=sql.110).aspx
    $ find /usr -name &quot;logging.properties&quot;
        /usr/lib/jvm/java-7-openjdk-amd64/jre/lib/logging.properties
        /usr/lib/jvm/java-8-oracle/jre/lib/logging.properties
            ... this one (check with: java -version)
    Default handler is the console. Unchanged line:
        # handlers = java.util.logging.ConsoleHandler
        handlers = java.util.logging.ConsoleHandler, java.util.logging.FileHandler
    Add line:
        com.microsoft.sqlserver.jdbc.level=FINEST
    Change logger level:
        java.util.logging.ConsoleHandler.level = FINEST
    OR configure file handler:
        java.util.logging.FileHandler.pattern = %h/java%u.log
        java.util.logging.FileHandler.limit = 5000000
        java.util.logging.FileHandler.count = 20
        java.util.logging.FileHandler.formatter = java.util.logging.SimpleFormatter
        java.util.logging.FileHandler.level = FINEST


    Python 3 changes -- not done, but some notes:

    $ sudo apt-get install python3-pip

    import bcrypt  # sudo apt-get install python3-bcrypt
    import configparser  # was: import ConfigParser
    import dateutil  # sudo apt-get install python3-dateutil
    import M2Crypto  # sudo apt-get install swig; sudo pip3 install M2Crypto  # INSTALLS BUT FAILS TO IMPORT
    import pytz  # sudo pip3 install pytz
    import regex  # sudo apt-get install python3-regex
    import sortedcontainers  # sudo pip3 install sortedcontainers


-------------------------------------------------------------------------------
??naming
-------------------------------------------------------------------------------

CRATE: Clinical Records Anonymisation and Text Extraction


===============================================================================
JDBC SQL tools
===============================================================================

- Squirrel SQL
    - Install

        wget http://downloads.sourceforge.net/project/squirrel-sql/1-stable/3.6.0/squirrel-sql-3.6-standard.jar?r=http%3A%2F%2Fsquirrel-sql.sourceforge.net%2F&amp;ts=1432028753&amp;use_mirror=netcologne

        # now rename the result to squirrel-sql-3.6-standard.jar

        java -jar squirrel-sql-3.6-standard.jar

        # install, picking Microsoft SQL Server and MySQL as plugins,
        # plus &quot;Multi Source&quot; and &quot;Data import&quot;
        # Will then run from its new directory, via

        squirrel-sql-3.6/squirrel-sql.sh &amp;

    - Configure SQL Server

        Windows &gt; View Drivers &gt; Microsoft MSSQL Server JDBC Driver
            &gt; Extra Class Path
            &gt; find sqljdbc_4.1/enu/sqljdbc41.jar

        Windows &gt; View Aliases &gt; Add Alias
            ... set up the database
            ... test connection
        URL defaults to:
            jdbc:sqlserver://&lt;server_name&gt;:1433;databaseName=&lt;db_name&gt;
        Since it didn&#39;t work, using this:
           jdbc:sqlserver://INSERT_IP_ADDRESS:1433;databaseName=INSERT_DB_NAME;responseBuffering=adaptive;selectMethod=cursor
        It copes with specifying the username/password in the dialogue box.

    - Configure MySQL

        Extra classpath is /usr/share/java/mysql.jar
        Beforehand: sudo apt-get install libmysql-java
        URL: jdbc:mysql://{host}:{port}/{database}

===============================================================================
Django app and project structure
===============================================================================

- want a single virtualenv
- Django app may want to access anonymisation classes e.g. data dictionary
- top-level Python programs should be distinct from imported files

- http://python-notes.curiousefficiency.org/en/latest/python_concepts/import_traps.html

===============================================================================
Profiling the Django app
===============================================================================

python -m cProfile -o c:\CRATE_PROFILE.profile crate_anon/tools/launch_cherrypy_server.py

===============================================================================
Static files, speed, etc.
===============================================================================

- Minimize the number of templates (e.g. remove action_only_form.html).
- At present we&#39;re using {% include %} to put CSS in.
- This would be faster with static URLs.
- However, the tricky bit is PDF generation, for which wkhtmltopdf needs to
  have embedded CSS (since we can&#39;t guarantee its network access to our own web
  server).
- Can this be managed better? If so, several things could go to static:
    - base.css
    - collapse.js
    - potentially a new fancier Javascript file for query building
- We could achieve this with our pdf_template_dict() function, which is called
  for all PDF generation. It could bake in appropriate CSS, by loading the
  static file directly in code (and caching the result).
- Similarly for e-mail generation, where CSS also needs to be embedded.
- Just define convenience functions:
        render_pdf_html_to_string(template, context)
        render_email_html_to_string(template, context)
- But the tricky bits:
    - collapse.js refers to static image files, and relative paths are from
      the HTML, not the JS, so &quot;./plus.gif&quot; doesn&#39;t work. It needs to know the
      URL prefix for static files, so that&#39;s a problem.
      - But we can split it: variable definition in HTML/template, and the rest
        in static JS.
- For email.css (included from base_email.html), speed isn&#39;t critical. Let&#39;s
  leave that as it is.
- Removed base_root.html, taking out one layer of regular indirection.
- Now, base_email.html and base_pdf.html have CSS passed to them by the
  convenience functions (extracted in Python). The web one, base.html, uses
  links to static files.
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h3><a href="../index.html">Table Of Contents</a></h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction/overview.html">1. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/package_elements.html">2. Package elements in brief</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/publications.html">3. Reference publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation/installation.html">4. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation/database_drivers.html">5. Databases and database drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../anonymisation/index.html">6. Anonymisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/index.html">7. Natural language processing (NLP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../website_config/index.html">8. Configuring the CRATE web interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../website_using/index.html">9. Using the CRATE web interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="ancillary_tools.html">10. Ancillary tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">11. Troubleshooting</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">12. Technical notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#resolved-bugs-elsewhere-previously-affecting-crate">12.1. Resolved bugs elsewhere, previously affecting CRATE</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cross-platform-hosting">12.2. Cross-platform hosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="#converting-to-sqlalchemy">12.3. Converting to SQLAlchemy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#installing-python-3-4-on-ubuntu-16-04">12.4. Installing Python 3.4 on Ubuntu 16.04</a></li>
<li class="toctree-l2"><a class="reference internal" href="#transaction-count-always-0-for-sql-server-prohibiting-create-fulltext-index">12.5. Transaction count always &gt;0 for SQL Server, prohibiting CREATE FULLTEXT INDEX</a></li>
<li class="toctree-l2"><a class="reference internal" href="#celery-test-email-rdbm-task-missing-1-required-positional-argument-self">12.6. Celery: test_email_rdbm_task() missing 1 required positional argument: ‘self’</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sql-comments">12.7. SQL comments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#webnotes-txt">12.8. webnotes.txt</a></li>
<li class="toctree-l2"><a class="reference internal" href="#notes-on-database-schemas-txt">12.9. notes_on_database_schemas.txt</a></li>
<li class="toctree-l2"><a class="reference internal" href="#old-notes-txt">12.10. old notes.txt</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="upgrading.html">13. Upgrading CRATE</a></li>
<li class="toctree-l1"><a class="reference internal" href="tcpip_ports.html">14. Common relevant TCP/IP ports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/index.html">15. Automatic documentation of source code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">16. Change log/history</a></li>
<li class="toctree-l1"><a class="reference internal" href="to_do.html">17. Things to do</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">18. Abbreviations and glossary</a></li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="troubleshooting.html"
                        title="previous chapter">11. Troubleshooting</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="upgrading.html"
                        title="next chapter">13. Upgrading CRATE</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/misc/technical_notes.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="upgrading.html" title="13. Upgrading CRATE"
             >next</a> |</li>
        <li class="right" >
          <a href="troubleshooting.html" title="11. Troubleshooting"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">CRATE  documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Rudolf Cardinal.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.5.
    </div>
  </body>
</html>